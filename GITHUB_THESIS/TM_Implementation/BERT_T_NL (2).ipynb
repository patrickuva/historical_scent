{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e69b28de-74bf-46d3-a672-8d107b8dc5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/arch/RHEL8/EB_production/2022/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages/paramiko/transport.py:236: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "#!pip install bertopic datasets accelerate bitsandbytes xformers adjustText\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from octis.dataset.dataset import Dataset\n",
    "from octis.optimization.optimizer import Optimizer\n",
    "from skopt.space.space import Real, Categorical, Integer\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "import time\n",
    "import en_core_web_sm\n",
    "\n",
    "\n",
    "optimizer=Optimizer()\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c231c4-60e1-448b-81d9-17590f92f34c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SETUP\n",
    "DATA = \"NL\"\n",
    "EM = \"emanjavacas/GysBERT\"\n",
    "EM2 = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "#jegormeister/bert-base-dutch-cased-snli\n",
    "#paraphrase-multilingual-MiniLM-L12-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6170d343-45b3-4224-84a0-d96c54535ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.load_custom_dataset_from_folder(DATA)\n",
    "docs = [\" \".join(words) for words in dataset.get_corpus()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5f6dde-d4e8-4539-adfa-86645593571e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd482405a6844d1bb3f6ff8d8a35293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(EM2)\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4b6481-1473-4668-84c7-1777913e060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, custom = DATA, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f7bc9f5-827e-492b-982c-a5fd9ebbdb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 20:24:26.864513: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512_VNNI\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-10 20:24:27.082229: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pspaargaren/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from evaluation_vis import Trainer\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac63b05-56ed-4e07-a190-219f67b95ddc",
   "metadata": {},
   "source": [
    "# BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8abdf9-25c0-4a0d-a022-d87c594af458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TC & TD CALCULATION\n",
    "for i in range(3):\n",
    "    custom = True\n",
    "    params = {\n",
    "        \"embedding_model\": embedding_model,\n",
    "        \"nr_topics\": [(i+1)*10 for i in range(5)],\n",
    "        \"min_topic_size\": 10,\n",
    "        #\"diversity\": None,\n",
    "        \"verbose\": True\n",
    "    }\n",
    "\n",
    "    trainer = Trainer(dataset=dataset,\n",
    "                        model_name=\"BERTopic\",\n",
    "                        params=params,\n",
    "                        bt_embeddings=embeddings,\n",
    "                        custom_dataset=custom,\n",
    "                        verbose=True)\n",
    "    results = trainer.train(save=f\"results/NL_mod/scores/bertopic_{i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1a24e4-7d9c-4e13-9d26-2499d996f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOPIC EXTRACTION\n",
    "custom = True\n",
    "params = {\n",
    "    \"embedding_model\": embedding_model,\n",
    "    \"nr_topics\": 15,\n",
    "    \"min_topic_size\": 10,\n",
    "    #\"diversity\": None,\n",
    "    \"verbose\": True\n",
    "}\n",
    "\n",
    "trainer = Trainer(dataset=dataset,\n",
    "                    model_name=\"BERTopic\",\n",
    "                    params=params,\n",
    "                    bt_embeddings=embeddings,\n",
    "                    custom_dataset=custom,\n",
    "                    verbose=True)\n",
    "results = trainer.train(save=f\"results/NL_mod/topics/bertopic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d70c3-6ae9-4857-933f-4671e3c413ea",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35700e-f5e9-4313-bf2c-5757368117fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, random_state in enumerate([0, 21, 42]):\n",
    "    dataset, custom = DATA, True\n",
    "    params = {\"num_topics\": [(i+1)*10 for i in range(5)], \"random_state\": random_state}\n",
    "\n",
    "    trainer = Trainer(dataset=dataset,\n",
    "                      model_name=\"LDA\",\n",
    "                      params=params,\n",
    "                      custom_dataset=custom,\n",
    "                      verbose=True)\n",
    "    results = trainer.train(save=f\"results/NL_mod/scores/lda_{i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131f37e1-1b43-4e7a-9361-00d5003932c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOPIC CREATION:\n",
    "dataset, custom = DATA, True\n",
    "params = {\"num_topics\": 15, \"random_state\": 42}#[(i+1)*10 for i in range(5)], \"random_state\": random_state}\n",
    "\n",
    "trainer = Trainer(dataset=dataset,\n",
    "                  model_name=\"LDA\",\n",
    "                  params=params,\n",
    "                  custom_dataset=custom,\n",
    "                  verbose=True)\n",
    "results = trainer.train(save=f\"results/NL_mod/topics/lda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbbe7ea-3611-4b92-bbda-22e699c692fe",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b77213-29ea-4b60-89fe-f71ca1fa56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, random_state in enumerate([0, 21, 42]):\n",
    "    dataset, custom = DATA, True\n",
    "    params = {\"num_topics\": [(i+1)*10 for i in range(5)], \"random_state\": random_state}\n",
    "\n",
    "    trainer = Trainer(dataset=dataset,\n",
    "                      model_name=\"NMF\",\n",
    "                      params=params,\n",
    "                      custom_dataset=custom,\n",
    "                      verbose=True)\n",
    "    results = trainer.train(save=f\"results/NL_mod/scores/nmf_{i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b636cfa-2144-4668-89c5-a8d261b0bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOPIC CREATION:\n",
    "dataset, custom = DATA, True\n",
    "params = {\"num_topics\": 15, \"random_state\": 42}#[(i+1)*10 for i in range(5)], \"random_state\": random_state}\n",
    "\n",
    "trainer = Trainer(dataset=dataset,\n",
    "                  model_name=\"NMF\",\n",
    "                  params=params,\n",
    "                  custom_dataset=custom,\n",
    "                  verbose=True)\n",
    "results = trainer.train(save=f\"results/NL_mod/topics/nmf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911a1d6-62b8-4b51-83d5-d5943017bb00",
   "metadata": {},
   "source": [
    "# CTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da5d11-8369-4760-b64e-80e4915ae329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9490339-0108-410a-ac42-2ef4022b4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TC & TD\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "#!pip install contextualized_topic_models\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "for i in range(1):\n",
    "    dataset, custom = DATA, True\n",
    "    params = {\n",
    "        \"n_components\": [(i+1)*10 for i in range(5)],\n",
    "        \"contextual_size\":768\n",
    "    }\n",
    "\n",
    "    trainer = Trainer(dataset=dataset,\n",
    "                      model_name=\"CTM_CUSTOM\",\n",
    "                      params=params,\n",
    "                      custom_dataset=custom,\n",
    "                      verbose=True)\n",
    "    results = trainer.train(save=f\"results/NL_mod/scores/ctm_{i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6348d2c5-2372-4d8a-b683-98a90fff69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOPIC CREATION\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "#!pip install contextualized_topic_models\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "#for i in range(3):\n",
    "dataset, custom = DATA, True\n",
    "params = {\n",
    "    \"n_components\": 15,#[(i+1)*10 for i in range(5)],\n",
    "    \"contextual_size\":768\n",
    "}\n",
    "\n",
    "trainer = Trainer(dataset=dataset,\n",
    "                  model_name=\"CTM_CUSTOM\",\n",
    "                  params=params,\n",
    "                  custom_dataset=custom,\n",
    "                  verbose=True)\n",
    "results = trainer.train(save=f\"results/NL_mod/topics/ctm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151438c0-86a5-4d7c-93e4-cf29b6e8f165",
   "metadata": {},
   "source": [
    "# Dynamic TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d48e1e90-a5eb-4f8d-9ca9-4820ea93f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETUP\n",
    "dDATA = \"NL_dtm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555400f1-dd4b-4b63-9210-70d06a64954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.load_custom_dataset_from_folder(dDATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0085da9-23ed-4eeb-ace4-1bddaed5db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/pspaargaren/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446a3c370cfb4aab8b6bc8ed2e50c41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "dataset, custom = dDATA, True\n",
    "from data_t_NL import DataLoader\n",
    "data_loader = DataLoader(dataset)\n",
    "_, timestamps = data_loader.load_docs()\n",
    "#print(timestamps)\n",
    "data = data_loader.load_octis(custom)\n",
    "data = [\" \".join(words) for words in data.get_corpus()]\n",
    "\n",
    "embedding_model = SentenceTransformer(EM2) #EM3\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b45520f9-f268-4493-b540-99980165399a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9997, 9997)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match indices\n",
    "import os\n",
    "os.listdir(f\"./{dataset}\")\n",
    "with open(f\"./{dataset}/indexes.txt\") as f:\n",
    "    indices = f.readlines()\n",
    "    \n",
    "indices = [int(index.split(\"\\n\")[0]) for index in indices]\n",
    "timestamps = [timestamp for index, timestamp in enumerate(timestamps) if index in indices]\n",
    "len(data), len(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fe2a6ad-dd80-4425-bcf0-7d9a6436881a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pspaargaren/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2024-06-10 20:24:41,536 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-06-10 20:25:18,319 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-06-10 20:25:18,320 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-06-10 20:25:18,826 - BERTopic - Cluster - Completed ✓\n",
      "2024-06-10 20:25:18,827 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-06-10 20:25:20,384 - BERTopic - Representation - Completed ✓\n",
      "2024-06-10 20:25:20,385 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2024-06-10 20:25:21,714 - BERTopic - Topic reduction - Reduced number of topics from 242 to 10\n",
      "10it [00:01,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esperana\n",
      "harmonien\n",
      "waanideen\n",
      "efezirs\n",
      "isral\n",
      "gesoleerd\n",
      "aron\n",
      "baum\n",
      "mystres\n",
      "brger\n",
      "normandi\n",
      "creer\n",
      "angoulme\n",
      "gelimineerd\n",
      "tween\n",
      "arons\n",
      "patinten\n",
      "itali\n",
      "azi\n",
      "indivaarder\n",
      "vogelvolire\n",
      "sicili\n",
      "gttlichen\n",
      "hermsilaos\n",
      "reen\n",
      "caster\n",
      "olin\n",
      "zeen\n",
      "frdrique\n",
      "zweetporin\n",
      "mattes\n",
      "genstalleerd\n",
      "coup\n"
     ]
    }
   ],
   "source": [
    "from evaluation import Trainer\n",
    "\n",
    "params = {\n",
    "        \"nr_topics\": 10,#[(i+1)*10 for i in range(5)],\n",
    "        \"min_topic_size\": 5,\n",
    "        \"verbose\": True,\n",
    "    }\n",
    "\n",
    "trainer = Trainer(dataset=dataset,\n",
    "                      model_name=\"BERTopic\",\n",
    "                      params=params,\n",
    "                      bt_embeddings=embeddings,\n",
    "                      custom_dataset=custom,\n",
    "                      bt_timestamps=timestamps,\n",
    "                      topk=5,\n",
    "                      bt_nr_bins=10,\n",
    "                      verbose=True)\n",
    "results = trainer.train(f\"NOT_NEEDED/D_NL_T_EVO_M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828b4d3-12e7-4aab-850f-d285139585f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
