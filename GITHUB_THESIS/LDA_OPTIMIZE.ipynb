{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cdf61896-5f4c-4390-937f-c9e02a26fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from octis.models.LDA import LDA\n",
    "from octis.dataset.dataset import Dataset\n",
    "from octis.optimization.optimizer import Optimizer\n",
    "from skopt.space.space import Real, Categorical, Integer\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.dataset.dataset import Dataset\n",
    "from skopt.space.space import Real, Categorical, Integer\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.optimization.optimizer import Optimizer\n",
    "optimizer=Optimizer()\n",
    "import time\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "dataset = Dataset()\n",
    "dataset.load_custom_dataset_from_folder(\"NL_OPT\")\n",
    "docs = [\" \".join(words) for words in dataset.get_corpus()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62d10b1b-862c-4c6f-ae37-aae1bc73b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class NeuralLDA(AVITM):\n",
      "    def __init__(\n",
      "        self, num_topics=10, activation='softplus', dropout=0.2,\n",
      "        learn_priors=True, batch_size=64, lr=2e-3, momentum=0.99,\n",
      "        solver='adam', num_epochs=100, reduce_on_plateau=False, prior_mean=0.0,\n",
      "        prior_variance=None, num_layers=2, num_neurons=100, num_samples=10,\n",
      "            use_partitions=True):\n",
      "        super().__init__(\n",
      "            num_topics=num_topics, model_type='LDA', activation=activation,\n",
      "            dropout=dropout, learn_priors=learn_priors, batch_size=batch_size,\n",
      "            lr=lr, momentum=momentum, solver=solver, num_epochs=num_epochs,\n",
      "            reduce_on_plateau=reduce_on_plateau, prior_mean=prior_mean,\n",
      "            prior_variance=prior_variance, num_layers=num_layers,\n",
      "            num_neurons=num_neurons, num_samples=num_samples,\n",
      "            use_partitions=use_partitions)\n",
      "\n",
      "    def train_model(self, dataset, hyperparameters=None, top_words=10):\n",
      "        return super().train_model(\n",
      "            dataset=dataset, hyperparameters=hyperparameters,\n",
      "            top_words=top_words)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from octis.models.NeuralLDA import NeuralLDA\n",
    "import inspect\n",
    "print(inspect.getsource(NeuralLDA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a612b98-d2c5-42f3-900e-ec27bfd305c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_topics=100, distributed=False, chunksize=2000,\n",
    "#         passes=1, update_every=1, alpha=\"symmetric\", eta=None, decay=0.5,\n",
    "#         offset=1.0, eval_every=10, iterations=50, gamma_threshold=0.001,\n",
    "#             random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b9e72ac-85cc-4d5b-b68e-b4a102a5f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_topics=10, activation='softplus', dropout=0.2,\n",
    "#         learn_priors=True, batch_size=64, lr=2e-3, momentum=0.99,\n",
    "#         solver='adam', num_epochs=100, reduce_on_plateau=False, prior_mean=0.0,\n",
    "#         prior_variance=None, num_layers=2, num_neurons=100, num_samples=10,\n",
    "#             use_partitions=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4df4a71-f65f-4bcc-abee-638a89788b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTING METRICS\n",
    "coherence = Coherence(texts=dataset.get_corpus(), measure = 'c_npmi')\n",
    "diversity = TopicDiversity(topk=10)\n",
    "\n",
    "#RUN CONFIGURATION\n",
    "optimization_runs=12\n",
    "model_runs=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ed321-e895-40f2-8584-ae8c42443937",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74e28092-3c92-4424-bc02-c75bf748dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LDA()\n",
    "\n",
    "search_space = {\n",
    "    \"num_topics\": [10,20,30,40,50],\n",
    "    \"alpha\": ['symmetric','asymmetric']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a49a8af2-357f-47f9-a48b-03e22b4756a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current call:  0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_partitioned_corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#OPTIMIZATION\u001b[39;00m\n\u001b[1;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m optimization_result \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoherence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimization_runs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_runs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdiversity\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# to keep track of other metrics\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults2/test_NLDA2//\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m duration \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/octis/optimization/optimizer.py:184\u001b[0m, in \u001b[0;36mOptimizer.optimize\u001b[0;34m(self, model, dataset, metric, search_space, extra_metrics, number_of_call, n_random_starts, initial_point_generator, optimization_type, model_runs, surrogate_model, kernel, acq_func, random_state, x0, y0, save_models, save_step, save_name, save_path, early_stop, early_step, plot_best_seen, plot_model, plot_name, log_scale_plot, topk)\u001b[0m\n\u001b[1;32m    181\u001b[0m opt \u001b[38;5;241m=\u001b[39m choose_optimizer(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# Perform Bayesian Optimization\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimization_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/octis/optimization/optimizer.py:323\u001b[0m, in \u001b[0;36mOptimizer._optimization_loop\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m     next_x \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mask()\n\u001b[0;32m--> 323\u001b[0m     f_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_objective_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# Update the opt using (next_x,f_val)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m res \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mtell(next_x, f_val)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/octis/optimization/optimizer.py:241\u001b[0m, in \u001b[0;36mOptimizer._objective_function\u001b[0;34m(self, hyperparameter_values)\u001b[0m\n\u001b[1;32m    235\u001b[0m different_model_runs_extra_metrics \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_metrics))]\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_runs):\n\u001b[1;32m    239\u001b[0m \n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# Prepare model\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# Score of the model\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\u001b[38;5;241m.\u001b[39mscore(model_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/octis/models/LDA.py:169\u001b[0m, in \u001b[0;36mLDA.train_model\u001b[0;34m(self, dataset, hyperparams, top_words)\u001b[0m\n\u001b[1;32m    166\u001b[0m     hyperparams \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_partitions:\n\u001b[0;32m--> 169\u001b[0m     train_corpus, test_corpus \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_partitioned_corpus\u001b[49m(\n\u001b[1;32m    170\u001b[0m         use_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     train_corpus \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_corpus()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_partitioned_corpus'"
     ]
    }
   ],
   "source": [
    "#OPTIMIZATION\n",
    "start = time.time()\n",
    "optimization_result = optimizer.optimize(\n",
    "    model, dataset, coherence, search_space, number_of_call=optimization_runs, \n",
    "    model_runs=model_runs, save_models=True, \n",
    "    extra_metrics=[diversity], # to keep track of other metrics\n",
    "    save_path='results2/test_NLDA2//')\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "optimization_result.save_to_csv('results_LDA3.csv')\n",
    "print('Optimizing model took: ' + str(round(duration)) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d658cb4-e131-49fc-b86a-d61760b20628",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralLDA(num_topics=10)\n",
    "search_space = {\n",
    "    \"activation\": ['softplus','sigmoid', 'relu'],\n",
    "    \"num_layers\" : [1,2,4,8], \n",
    "    \"num_neurons\": [50,100,200,300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eaf5aac5-162e-4c7e-bea9-8d635581a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current call:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pspaargaren/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1320: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tSamples: [19058/1905800]\tTrain Loss: 1115.908307042974\tTime: 0:00:05.344867\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#OPTIMIZATION\u001b[39;00m\n\u001b[1;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m optimization_result \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoherence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimization_runs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_runs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdiversity\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# to keep track of other metrics\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults/test_neuralLDA//\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m duration \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/octis/optimization/optimizer.py:184\u001b[0m, in \u001b[0;36mOptimizer.optimize\u001b[0;34m(self, model, dataset, metric, search_space, extra_metrics, number_of_call, n_random_starts, initial_point_generator, optimization_type, model_runs, surrogate_model, kernel, acq_func, random_state, x0, y0, save_models, save_step, save_name, save_path, early_stop, early_step, plot_best_seen, plot_model, plot_name, log_scale_plot, topk)\u001b[0m\n\u001b[1;32m    181\u001b[0m opt \u001b[38;5;241m=\u001b[39m choose_optimizer(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# Perform Bayesian Optimization\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimization_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/octis/optimization/optimizer.py:323\u001b[0m, in \u001b[0;36mOptimizer._optimization_loop\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m     next_x \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mask()\n\u001b[0;32m--> 323\u001b[0m     f_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_objective_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# Update the opt using (next_x,f_val)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m res \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mtell(next_x, f_val)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/octis/optimization/optimizer.py:241\u001b[0m, in \u001b[0;36mOptimizer._objective_function\u001b[0;34m(self, hyperparameter_values)\u001b[0m\n\u001b[1;32m    235\u001b[0m different_model_runs_extra_metrics \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_metrics))]\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_runs):\n\u001b[1;32m    239\u001b[0m \n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# Prepare model\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# Score of the model\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\u001b[38;5;241m.\u001b[39mscore(model_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/octis/models/NeuralLDA.py:21\u001b[0m, in \u001b[0;36mNeuralLDA.train_model\u001b[0;34m(self, dataset, hyperparameters, top_words)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, hyperparameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, top_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_words\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/octis/models/pytorchavitm/AVITM.py:105\u001b[0m, in \u001b[0;36mAVITM.train_model\u001b[0;34m(self, dataset, hyperparameters, top_words)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m avitm_model\u001b[38;5;241m.\u001b[39mAVITM_model(\n\u001b[1;32m     93\u001b[0m     input_size\u001b[38;5;241m=\u001b[39minput_size, num_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_topics\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     94\u001b[0m     model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m], hidden_sizes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_sizes\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     topic_prior_variance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprior_variance\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    102\u001b[0m )\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_partitions:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(x_test)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/octis/models/pytorchavitm/avitm/avitm_model.py:268\u001b[0m, in \u001b[0;36mAVITM_model.fit\u001b[0;34m(self, train_dataset, validation_dataset, save_dir)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_loss_train \u001b[38;5;241m=\u001b[39m train_loss\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     validation_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_data_loader_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# train epoch\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     s \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m/sw/arch/RHEL8/EB_production/2022/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:347\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 347\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/sw/arch/RHEL8/EB_production/2022/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "#OPTIMIZATION\n",
    "start = time.time()\n",
    "optimization_result = optimizer.optimize(\n",
    "    model, dataset, coherence, search_space, number_of_call=optimization_runs, \n",
    "    model_runs=model_runs, save_models=True, \n",
    "    extra_metrics=[diversity], # to keep track of other metrics\n",
    "    save_path='results/test_neuralLDA//')\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "optimization_result.save_to_csv(\"results_neuralLDA.csv\")\n",
    "print('Optimizing model took: ' + str(round(duration)) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee7195-be2e-4f79-ba0b-2496dec62b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer()\n",
    "json_path = 'results2/test_NLDA2/result.json'\n",
    "optimizer.resume_optimization(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e01f5-299d-4fba-877e-a53bba373ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "results = json.load(open(\"results2/test_LDA2/result.json\",'r'))\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fad942-6b84-4b14-ad3a-8f591a6bd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Coherence score (c_npmi)')\n",
    "plt.title('Median coherence score per iteration')\n",
    "plt.plot(results[\"f_val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8758b-04e9-4948-b8d8-274c244676f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[ 'f_val'].index(max(results[ 'f_val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bcea87-6772-41d7-80a7-e430f704fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([results['x_iters'][parameter][0] for parameter in results['x_iters'].keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17dc6e8-2a12-4597-a543-1400979fdbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
